"""
í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê²€ì¦ìš© wav íŒŒì¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ í™•ì¸
"""
import os
import sys
import torch
import librosa
import numpy as np
from pathlib import Path

sys.path.append('.')
from models import ASTModel

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Device: {DEVICE}")


def load_audio(file_path, duration=3, sr=16000, n_mels=80):
    """ì˜¤ë””ì˜¤ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    try:
        audio, _ = librosa.load(file_path, sr=sr, mono=True)
        audio = librosa.util.fix_length(audio, size=sr * duration)
        
        # Mel-spectrogram ë³€í™˜
        mel_spec = librosa.feature.melspectrogram(
            y=audio, sr=sr, n_mels=n_mels,
            n_fft=1024, hop_length=320
        )
        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
        
        # ì •ê·œí™”
        mel_spec_db = (mel_spec_db - mel_spec_db.mean()) / (mel_spec_db.std() + 1e-8)
        
        return torch.FloatTensor(mel_spec_db).unsqueeze(0)
    except Exception as e:
        print(f"ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def predict_single_file(model, file_path):
    """ë‹¨ì¼ íŒŒì¼ ì˜ˆì¸¡"""
    audio_tensor = load_audio(file_path)
    if audio_tensor is None:
        return None, None
    
    audio_tensor = audio_tensor.unsqueeze(0).to(DEVICE)  # (1, 1, 80, T)
    
    with torch.no_grad():
        output = model(audio_tensor)
        probs = torch.softmax(output, dim=1)[0]
        predicted_class = probs.argmax().item()
        confidence = probs[predicted_class].item()
    
    class_names = ["ì •ìƒ(NORMAL)", "ìœ„ê¸‰(EMERGENCY)"]
    return class_names[predicted_class], confidence


def test_folder(model, folder_path):
    """í´ë” ë‚´ ëª¨ë“  wav íŒŒì¼ í…ŒìŠ¤íŠ¸"""
    wav_files = list(Path(folder_path).rglob('*.wav'))
    
    if not wav_files:
        print(f"âŒ {folder_path}ì— wav íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“‚ í…ŒìŠ¤íŠ¸ í´ë”: {folder_path}")
    print(f"   ì´ {len(wav_files)}ê°œ íŒŒì¼ ë°œê²¬\n")
    print("="*70)
    
    results = {"ì •ìƒ(NORMAL)": 0, "ìœ„ê¸‰(EMERGENCY)": 0}
    
    for i, file_path in enumerate(wav_files, 1):
        prediction, confidence = predict_single_file(model, str(file_path))
        
        if prediction is None:
            continue
        
        results[prediction] += 1
        
        # ê²°ê³¼ ì¶œë ¥
        status_icon = "ğŸš¨" if "ìœ„ê¸‰" in prediction else "âœ…"
        print(f"{status_icon} [{i:3d}] {file_path.name}")
        print(f"        ì˜ˆì¸¡: {prediction} (ì‹ ë¢°ë„: {confidence*100:.1f}%)")
        print("-"*70)
    
    print("\n" + "="*70)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*70)
    print(f"  âœ… ì •ìƒ(NORMAL):    {results['ì •ìƒ(NORMAL)']:3d}ê°œ")
    print(f"  ğŸš¨ ìœ„ê¸‰(EMERGENCY): {results['ìœ„ê¸‰(EMERGENCY)']:3d}ê°œ")
    print(f"  ğŸ“ ì´ íŒŒì¼:         {len(wav_files):3d}ê°œ")
    print("="*70)


def main():
    print("="*70)
    print("í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë„êµ¬")
    print("="*70)
    
    # ëª¨ë¸ ë¡œë“œ
    model_path = "models/ast_best.pth"
    if not os.path.exists(model_path):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        print("   ë¨¼ì € train_scream_model.pyë¡œ í•™ìŠµì„ ì§„í–‰í•˜ì„¸ìš”.")
        return
    
    print(f"\nğŸ“¦ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
    model = ASTModel(num_classes=2).to(DEVICE)
    model.load_state_dict(torch.load(model_path, map_location=DEVICE))
    model.eval()
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")
    
    # ì‚¬ìš©ë²• ì•ˆë‚´
    print("\nì‚¬ìš©ë²•:")
    print("  1. ë‹¨ì¼ íŒŒì¼ í…ŒìŠ¤íŠ¸: python test_model.py <íŒŒì¼ê²½ë¡œ>")
    print("  2. í´ë” í…ŒìŠ¤íŠ¸:     python test_model.py <í´ë”ê²½ë¡œ>")
    print("  3. ëŒ€í™”í˜• ëª¨ë“œ:     python test_model.py\n")
    
    # ì¸ìê°€ ìˆìœ¼ë©´ í•´ë‹¹ ê²½ë¡œ í…ŒìŠ¤íŠ¸
    if len(sys.argv) > 1:
        test_path = sys.argv[1]
        
        if os.path.isfile(test_path):
            # ë‹¨ì¼ íŒŒì¼
            print(f"ğŸ“„ ë‹¨ì¼ íŒŒì¼ í…ŒìŠ¤íŠ¸: {test_path}\n")
            prediction, confidence = predict_single_file(model, test_path)
            if prediction:
                status_icon = "ğŸš¨" if "ìœ„ê¸‰" in prediction else "âœ…"
                print(f"{status_icon} ì˜ˆì¸¡: {prediction}")
                print(f"   ì‹ ë¢°ë„: {confidence*100:.1f}%")
        
        elif os.path.isdir(test_path):
            # í´ë” í…ŒìŠ¤íŠ¸
            test_folder(model, test_path)
        
        else:
            print(f"âŒ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_path}")
    
    else:
        # ëŒ€í™”í˜• ëª¨ë“œ
        while True:
            print("\n" + "="*70)
            user_input = input("í…ŒìŠ¤íŠ¸í•  íŒŒì¼/í´ë” ê²½ë¡œ ì…ë ¥ (ì¢…ë£Œ: q): ").strip()
            
            if user_input.lower() == 'q':
                print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if not os.path.exists(user_input):
                print(f"âŒ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {user_input}")
                continue
            
            if os.path.isfile(user_input):
                prediction, confidence = predict_single_file(model, user_input)
                if prediction:
                    status_icon = "ğŸš¨" if "ìœ„ê¸‰" in prediction else "âœ…"
                    print(f"\n{status_icon} ì˜ˆì¸¡: {prediction}")
                    print(f"   ì‹ ë¢°ë„: {confidence*100:.1f}%")
            
            elif os.path.isdir(user_input):
                test_folder(model, user_input)


if __name__ == "__main__":
    main()

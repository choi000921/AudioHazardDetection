"""
CHANGED: íŒ€ì› ì¶”ë¡  ì½”ë“œ ì—°ê²° FastAPI ì„œë²„
ì‹¤ì œ ScreamDetectionPipelineì„ ì‚¬ìš©í•˜ëŠ” AI ì„œë²„
"""

import os
import logging
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import tempfile
from src.inference_adapter import predict

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Alertory AI Server", version="1.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:8080", "http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {"message": "Alertory AI Server", "status": "healthy"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "message": "AI ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤."}

@app.post("/predict")
async def predict_audio(file: UploadFile = File(...)):
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ì•„ì„œ ì‘ê¸‰ìƒí™© ì—¬ë¶€ë¥¼ íŒë³„
    
    Returns:
        {
            "label": str,        # SCREAM, Normal ë“±
            "confidence": float, # 0-100 ì‹ ë¢°ë„
            "text": str,         # ê²°ê³¼ ì„¤ëª… í…ìŠ¤íŠ¸
            "is_danger": bool    # ìœ„í—˜ ìƒí™© ì—¬ë¶€
        }
    """
    temp_file_path = None
    
    try:
        # íŒŒì¼ í™•ì¥ì ê²€ì¦
        if not file.filename:
            raise HTTPException(status_code=400, detail="íŒŒì¼ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        file_ext = os.path.splitext(file.filename)[1].lower()
        allowed_extensions = ['.wav', '.mp3', '.flac', '.m4a', '.webm', '.aac', '.ogg']
        
        if file_ext not in allowed_extensions:
            raise HTTPException(
                status_code=400, 
                detail=f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}. ì§€ì› í˜•ì‹: {', '.join(allowed_extensions)}"
            )
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_file:
            temp_file_path = temp_file.name
            content = await file.read()
            temp_file.write(content)
        
        logger.info(f"íŒŒì¼ ìˆ˜ì‹ : {file.filename} ({len(content)} bytes)")
        
        # ì¶”ë¡  ì‹¤í–‰
        result = predict(temp_file_path)
        
        logger.info(f"ì¶”ë¡  ì™„ë£Œ: {result}")
        return result
        
    except HTTPException:
        raise
    except FileNotFoundError as e:
        logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {e}")
        raise HTTPException(status_code=400, detail="ì—…ë¡œë“œëœ íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if temp_file_path and os.path.exists(temp_file_path):
            try:
                os.unlink(temp_file_path)
            except Exception as e:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    import uvicorn
    
    logger.info("ğŸš€ Alertory AI Server ì‹œì‘ ì¤‘...")
    logger.info("ğŸ“¡ í¬íŠ¸: 8001")
    logger.info("ğŸ”— ì—”ë“œí¬ì¸íŠ¸: http://localhost:8001/predict")
    
    uvicorn.run(app, host="0.0.0.0", port=8001)

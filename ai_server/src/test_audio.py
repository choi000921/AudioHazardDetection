import joblib
import numpy as np
import librosa
import sys
import os
import warnings
import re
import torch
from feature_extractor import AudioFeatureExtractor

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore")

# Whisper ëª¨ë¸ ë¡œë“œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ small ì‚¬ìš©)
try:
    import whisper
    # CUDA ì‚¬ìš© ê°€ëŠ¥ ì‹œ GPUë¡œ ë¡œë“œ
    device = "cuda" if torch.cuda.is_available() else "cpu"
    whisper_model = whisper.load_model("small").to(device)
except ImportError:
    whisper_model = None

def estimate_gender(y, sr):
    """ì£¼íŒŒìˆ˜ ë¶„ì„ì„ í†µí•œ ì„±ë³„ ì¶”ì •"""
    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
    pitch_values = [pitches[magnitudes[:, t].argmax(), t] for t in range(pitches.shape[1]) 
                    if 50 < pitches[magnitudes[:, t].argmax(), t] < 500]
    if not pitch_values: return "íŒë³„ ë¶ˆê°€"
    return "ë‚¨ì„± ì¶”ì •" if np.mean(pitch_values) < 165 else "ì—¬ì„± ì¶”ì •"

def detect_keywords(file_path):
    """Whisperë¥¼ ì´ìš©í•œ í‚¤ì›Œë“œ ê°ì§€ ë° ì‹ ë¢°ë„ ë¶„ì„"""
    if whisper_model is None: return "STT ì—”ì§„ ë¯¸ì„¤ì¹˜", False, 1.0

    options = {
        "language": "ko",
        "beam_size": 5,
        "fp16": torch.cuda.is_available(),
        "temperature": 0,
        "no_speech_threshold": 0.5, # ì†ŒìŒ í•„í„°ë§ ê¸°ì¤€ ê°•í™”
    }
    
    try:
        result = whisper_model.transcribe(file_path, **options)
        text = result['text'].strip()
        
        # ë§ì†Œë¦¬ê°€ ì•„ë‹ í™•ë¥  (ë†’ì„ìˆ˜ë¡ ê¸°ê³„ ì†ŒìŒì¼ ê°€ëŠ¥ì„± í¼)
        # result['segments'][0]ê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
        no_speech_prob = result['segments'][0]['no_speech_prob'] if result['segments'] else 1.0
        
        # í…ìŠ¤íŠ¸ ì •ì œ
        text = re.sub(r'[^\w\sê°€-í£]', '', text) 
        has_hangul = bool(re.search('[ê°€-í£]', text))
        display_text = text if has_hangul and len(text) >= 1 else "(ìŒì„± í™•ì¸ ë¶ˆê°€)"
        
        # ìœ„í—˜ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        danger_keywords = ["ì‚´ë ¤", "ë„ì™€", "ì‚¬ëŒ", "ì‹ ê³ ", "ê°•ë„", "ì‚¬ê³ ", "ìœ„í—˜", "ì¡°ì‹¬", "ì‚¬ë‚˜ì›Œ", "ë¬¼ì–´", "ì•„ì•¼"]
        is_dangerous = any(word in text for word in danger_keywords)
        
        return display_text, is_dangerous, no_speech_prob
    except Exception:
        return "(ë¶„ì„ ì˜¤ë¥˜)", False, 1.0

def predict_audio(file_path):
    try:
        # 1. ê³ ë„í™”ëœ ëª¨ë¸ ë° êµ¬ì„±ìš”ì†Œ ë¡œë“œ
        model = joblib.load('best_voice_model_xgb.pkl')
        scaler = joblib.load('scaler.pkl')
        le = joblib.load('label_encoder.pkl')
        
        # 2. íŠ¹ì§• ì¶”ì¶œ (Delta, ZCR ë“± í¬í•¨ëœ 514ì°¨ì›)
        extractor = AudioFeatureExtractor(duration=3)
        features = extractor.extract_mel_features(file_path)
        
        if features is None:
            print("íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # 3. ML ëª¨ë¸ ì˜ˆì¸¡ (ë¬¼ë¦¬ì  íŠ¹ì§• ê¸°ë°˜)
        features_scaled = scaler.transform(features.reshape(1, -1))
        probability = model.predict_proba(features_scaled)
        confidence = np.max(probability) * 100
        raw_label = le.inverse_transform([np.argmax(probability)])[0]

        # 4. Whisper ìƒì„¸ ë¶„ì„ (ì–¸ì–´ì  ë¬¸ë§¥ ê¸°ë°˜)
        detected_text, has_danger_word, no_speech_prob = detect_keywords(file_path)
        
        # 5. ìµœì¢… íŒì • ë¡œì§ (Hybrid Decision)
        # ìƒí™© A: ë¹„ëª…(Scream)ìœ¼ë¡œ íŒë‹¨ë˜ê³  í™•ì‹ ë„ê°€ ë§¤ìš° ë†’ì„ ë•Œ (90% ì´ìƒ)
        # ìƒí™© B: ìŒì„± ê°ì§€ ì¤‘ ìœ„í—˜ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì—ˆì„ ë•Œ
        # ìƒí™© C: ë¹„ëª…ìœ¼ë¡œ íŒë‹¨ë˜ì—ˆìœ¼ë‚˜ Whisperê°€ ì†ŒìŒì´ë¼ê³  íŒë‹¨(no_speech_prob > 0.8)í•˜ë©´ ì‹ ì¤‘íˆ ì²˜ë¦¬
        
        is_emergency = False
        if raw_label == 'Scream' and confidence >= 90.0:
            is_emergency = True
        elif (raw_label == 'Scream' or raw_label == 'ìŒì„± í´ë˜ìŠ¤') and has_danger_word:
            is_emergency = True
        
        # ìµœì¢… ê²°ê³¼ ì¶œë ¥ ì„¤ì •
        if is_emergency:
            result_status = "ğŸš¨ ì‘ê¸‰ìƒí™© ê°ì§€ (Emergency)"
        elif (raw_label == 'Scream' or raw_label == 'ìŒì„± í´ë˜ìŠ¤') and confidence >= 70.0:
            result_status = "ğŸ“¢ ìŒì„± ê°ì§€ (Normal/Voice)"
        else:
            result_status = "âœ… ì •ìƒ ìƒíƒœ (Background/Noise)"

        # ì„±ë³„ ë° êµ­ì  ë¶„ì„ (ìŒì„±ì¸ ê²½ìš°ì—ë§Œ)
        if "ì •ìƒ" not in result_status:
            y, sr = librosa.load(file_path)
            gender = estimate_gender(y, sr)
            nationality = "ë‚´êµ­ì¸" if "ë‚´êµ­ì¸" in file_path else "ì™¸êµ­ì¸/ë¯¸ë¶„ë¥˜"
            detail_msg = f"ë‚´ìš©: '{detected_text}'"
        else:
            gender, nationality, detail_msg = "-", "-", "íŠ¹ì´ì‚¬í•­ ì—†ìŒ"

        # ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥
        print("\n" + "="*70)
        print(f" [íŒŒì¼ëª…]: {os.path.basename(file_path)}")
        print(f" ê²°ê³¼:    {result_status}")
        print(f" MLë¶„ë¥˜:  {raw_label} (í™•ì‹ ë„: {confidence:.2f}%)")
        if "ì •ìƒ" not in result_status:
            print(f" ì„±ë³„/êµ­ì : {gender}  |  {nationality}")
            print(f" STTë‚´ìš©:  {detail_msg} (ì†ŒìŒí™•ë¥ : {no_speech_prob*100:.1f}%)")
        print("="*70 + "\n")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    if len(sys.argv) >= 2:
        predict_audio(sys.argv[1])
    else:
        print("ì‚¬ìš©ë²•: python3 test_audio.py <íŒŒì¼ê²½ë¡œ>")